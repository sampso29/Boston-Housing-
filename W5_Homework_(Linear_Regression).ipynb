{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W5_Homework (Linear Regression).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sampso29/Boston-Housing-/blob/master/W5_Homework_(Linear_Regression).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tUHX52tF4X1"
      },
      "source": [
        "## Assignment for Module 5, Training Models\n",
        "\n",
        "In this assignment you will train different models on a given data set, and find the one that performs best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBACajJAF4X2"
      },
      "source": [
        "### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k3UBfb2F4X3"
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM5vyAxBF4X5"
      },
      "source": [
        "fetch_housing_data()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw_CY6LdF4X8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95lsxBveF4X-"
      },
      "source": [
        "housing = load_housing_data()\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_DYY-EC47rC",
        "outputId": "b9eedbb9-1e8c-4c73-f1ac-324ea5b1155b"
      },
      "source": [
        "housing.info()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           20640 non-null  float64\n",
            " 1   latitude            20640 non-null  float64\n",
            " 2   housing_median_age  20640 non-null  float64\n",
            " 3   total_rooms         20640 non-null  float64\n",
            " 4   total_bedrooms      20433 non-null  float64\n",
            " 5   population          20640 non-null  float64\n",
            " 6   households          20640 non-null  float64\n",
            " 7   median_income       20640 non-null  float64\n",
            " 8   median_house_value  20640 non-null  float64\n",
            " 9   ocean_proximity     20640 non-null  object \n",
            "dtypes: float64(9), object(1)\n",
            "memory usage: 1.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxHn4OCXEGK0",
        "outputId": "7358774f-f4cb-4a57-e667-d70bff937f53"
      },
      "source": [
        "housing.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20640, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrbmmdxBF4YA"
      },
      "source": [
        "### Fix the categories in the categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyOHgLhzF4YA"
      },
      "source": [
        "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
        "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFADowUPF4YD"
      },
      "source": [
        "### Add 2 more features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCvRIvaNF4YD"
      },
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq-lhhUVF4YF"
      },
      "source": [
        "### Fix missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "857cBmTlF4YG"
      },
      "source": [
        "median = housing[\"total_bedrooms\"].median()\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD62mLewF4YJ"
      },
      "source": [
        "### Create dummy variables based on the categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na_1d0RGF4YK"
      },
      "source": [
        "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
        "housing = housing.drop('ocean_proximity', axis=1)\n",
        "housing = housing.join(one_hot)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTPVdqn4F4YN"
      },
      "source": [
        "### Check the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QsdjKqjtZQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da898eb7-9160-450b-d857-0752e92d4502"
      },
      "source": [
        "housing.info()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 16 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   longitude                 20640 non-null  float64\n",
            " 1   latitude                  20640 non-null  float64\n",
            " 2   housing_median_age        20640 non-null  float64\n",
            " 3   total_rooms               20640 non-null  float64\n",
            " 4   total_bedrooms            20640 non-null  float64\n",
            " 5   population                20640 non-null  float64\n",
            " 6   households                20640 non-null  float64\n",
            " 7   median_income             20640 non-null  float64\n",
            " 8   median_house_value        20640 non-null  float64\n",
            " 9   rooms_per_household       20640 non-null  float64\n",
            " 10  population_per_household  20640 non-null  float64\n",
            " 11  INLAND                    20640 non-null  uint8  \n",
            " 12  ISLAND                    20640 non-null  uint8  \n",
            " 13  LESS_1H_OCEAN             20640 non-null  uint8  \n",
            " 14  NEAR_BAY                  20640 non-null  uint8  \n",
            " 15  NEAR_OCEAN                20640 non-null  uint8  \n",
            "dtypes: float64(11), uint8(5)\n",
            "memory usage: 1.8 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXW3dSMnF4YQ"
      },
      "source": [
        "# ASSIGNMENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaFO-RM4F4YQ"
      },
      "source": [
        "### 1. Partition into train and test\n",
        "\n",
        "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
        "\n",
        "You can use the 70% for training set as both training and validation by using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpxuUsunF4YR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(housing, test_size=0.3, random_state= 42)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVBdNm8S5z6I",
        "outputId": "6eef62bf-f144-472c-b8ad-579e64291c0e"
      },
      "source": [
        "train_set.info()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 14448 entries, 7061 to 15795\n",
            "Data columns (total 16 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   longitude                 14448 non-null  float64\n",
            " 1   latitude                  14448 non-null  float64\n",
            " 2   housing_median_age        14448 non-null  float64\n",
            " 3   total_rooms               14448 non-null  float64\n",
            " 4   total_bedrooms            14448 non-null  float64\n",
            " 5   population                14448 non-null  float64\n",
            " 6   households                14448 non-null  float64\n",
            " 7   median_income             14448 non-null  float64\n",
            " 8   median_house_value        14448 non-null  float64\n",
            " 9   rooms_per_household       14448 non-null  float64\n",
            " 10  population_per_household  14448 non-null  float64\n",
            " 11  INLAND                    14448 non-null  uint8  \n",
            " 12  ISLAND                    14448 non-null  uint8  \n",
            " 13  LESS_1H_OCEAN             14448 non-null  uint8  \n",
            " 14  NEAR_BAY                  14448 non-null  uint8  \n",
            " 15  NEAR_OCEAN                14448 non-null  uint8  \n",
            "dtypes: float64(11), uint8(5)\n",
            "memory usage: 1.4 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtqROes7552B",
        "outputId": "1e4b52cc-8caa-4541-931c-bee3bbb9bda3"
      },
      "source": [
        "test_set.info()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6192 entries, 20046 to 5786\n",
            "Data columns (total 16 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   longitude                 6192 non-null   float64\n",
            " 1   latitude                  6192 non-null   float64\n",
            " 2   housing_median_age        6192 non-null   float64\n",
            " 3   total_rooms               6192 non-null   float64\n",
            " 4   total_bedrooms            6192 non-null   float64\n",
            " 5   population                6192 non-null   float64\n",
            " 6   households                6192 non-null   float64\n",
            " 7   median_income             6192 non-null   float64\n",
            " 8   median_house_value        6192 non-null   float64\n",
            " 9   rooms_per_household       6192 non-null   float64\n",
            " 10  population_per_household  6192 non-null   float64\n",
            " 11  INLAND                    6192 non-null   uint8  \n",
            " 12  ISLAND                    6192 non-null   uint8  \n",
            " 13  LESS_1H_OCEAN             6192 non-null   uint8  \n",
            " 14  NEAR_BAY                  6192 non-null   uint8  \n",
            " 15  NEAR_OCEAN                6192 non-null   uint8  \n",
            "dtypes: float64(11), uint8(5)\n",
            "memory usage: 610.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qastIUuF4YT"
      },
      "source": [
        "### Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU7j7IXtF4YU"
      },
      "source": [
        "target = 'median_house_value'\n",
        "features = list(train_set.columns)\n",
        "features = [f for f in features if f!=target]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNpSVfsVF4YW"
      },
      "source": [
        "X_tr = train_set[features]\n",
        "y_tr = train_set[[target]]\n",
        "\n",
        "X_te = test_set[features]\n",
        "y_te = test_set[[target]]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATPrnjgCF4YY"
      },
      "source": [
        "### 2. Polynomial transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2bkA5IiF4YY"
      },
      "source": [
        "Use PolynomialFeatures from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5vDs_O4F4Ya"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(2)\n",
        "poly.fit(X_tr)\n",
        "X_tr = poly.transform(X_tr)\n",
        "X_te = poly.transform(X_te)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmLtFeRl6112",
        "outputId": "6c98eff1-9bec-4536-e7a4-f86fa1858817"
      },
      "source": [
        "X_tr.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14448, 136)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5F1Mcye6-MQ",
        "outputId": "c1fef245-ef48-4fa5-bdd3-c3e37e1c0097"
      },
      "source": [
        "X_te.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6192, 136)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwqAVP6MF4Yc"
      },
      "source": [
        "##### You should obtain X_tr and X_te with 136 columns each, since originally you had 15 features.\n",
        "\n",
        "##### With m original features, the new added polynomial features of degree 2 are: $(m^2-m)/2+m+1$. Why?\n",
        "\n",
        "##### These, plus the original features gives a total of  $(m^2-m)/2+2m+1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vDZwfMEF4Yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed18f25-d78f-4c06-b33c-ee0bdbf43234"
      },
      "source": [
        "print(\"Original number of features: \"+str(len(features)))\n",
        "print(\"Final number of features: \"+str(X_tr.shape[1]))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original number of features: 15\n",
            "Final number of features: 136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LxVLPiYF4Yh"
      },
      "source": [
        "### 3. Scaling features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbEpL-eHF4Yi"
      },
      "source": [
        "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGzLl5PfF4Yi"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_tr)\n",
        "X_tr_scaled = scaler.transform(X_tr)\n",
        "X_te_scaled = scaler.transform(X_te)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jjBUZuHF4Yk"
      },
      "source": [
        "#### Comparing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdPmOxFWF4Yl"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rPoxsuaF4Yo"
      },
      "source": [
        "### 4. Linear regression on original features (no transformations) --- benchmark\n",
        "\n",
        "#### Your goal is to find the model that minimizes the rmse score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfrzQ5fcF4Yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e83b603-8a08-42fe-bd7e-212a75fa003d"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [70142.55721218 67456.39127204 67318.3258893  70866.26065275]\n",
            "Mean: 68945.88375656855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7C8iKxlF4Yq"
      },
      "source": [
        "### 5. Linear regression  (on transformed features: polynomial transformation + scaling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBNvAgzPF4Yr"
      },
      "source": [
        "Now do as in 4 but with the original and transformed features (136 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwCF3T-UF4Ys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62055930-33b8-4529-c385-09e85cfc431b"
      },
      "source": [
        "poly_scores = cross_val_score(LinearRegression(), X_tr_scaled, y_tr, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "poly_rmse_scores = np.sqrt(-poly_scores)\n",
        "display_scores(poly_rmse_scores)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [1.09626586e+16 2.09837264e+15 1.10535405e+15 9.35143630e+13]\n",
            "Mean: 3564974918764342.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dehcVw3F4Yu"
      },
      "source": [
        "If the error on the cross-validation is too high it is because the model is over-fitting. Regularization is needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_4XGtmFF4Yv"
      },
      "source": [
        "### 6. Ridge regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NRXkacQF4Yv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ed7285-0420-4f0b-d963-5c219433f5ed"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
        "grid_search_rr = GridSearchCV(Ridge(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "grid_search_rr.fit(X_tr_scaled, y_tr)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                             max_iter=None, normalize=False, random_state=None,\n",
              "                             solver='auto', tol=0.001),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1000]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxRHwN9eF4Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671674f8-476d-46f1-8910-461b28774b71"
      },
      "source": [
        "print(grid_search_rr.best_params_)\n",
        "print(np.sqrt(-grid_search_rr.best_score_))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1000}\n",
            "67204.15300429483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWg7waJKF4Yz"
      },
      "source": [
        "### 7. Lasso regression\n",
        "\n",
        "Now do the same as in 6 but with Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2n0rkctF4Y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f58a32-b8e1-4e59-c336-a889be6a5725"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
        "grid_search_lasso = GridSearchCV(Lasso(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "grid_search_lasso.fit(X_tr_scaled, y_tr)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18961421524054.445, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18976456530479.066, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18637870076925.305, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18957816350912.86, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18971070833245.98, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18631928456197.633, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18921808319603.117, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18916938097492.996, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18572475032211.688, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18565974014721.547, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18346603933302.836, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17970320929764.8, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14876162372318.746, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12900410469895.8, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13504640558433.562, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 450090246640.5, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1201252581101.1094, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1253726042924.836, tolerance: 12886300597.558662\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                             max_iter=1000, normalize=False, positive=False,\n",
              "                             precompute=False, random_state=None,\n",
              "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 1000]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9pOYAai_iix",
        "outputId": "e13242ea-0301-49d4-d457-fab55d77643f"
      },
      "source": [
        "print(grid_search_lasso.best_params_)\n",
        "print(np.sqrt(-grid_search_lasso.best_score_))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1000}\n",
            "66619.6312718291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jDQEI4aF4Y3"
      },
      "source": [
        "### 8. Elastic Net regression\n",
        "\n",
        "Do the same as in 6 and 7, but now with Elastic Net. However, the grid search should be over the parameters alpha and  l 1ratio. Use just 3 values for l1_ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TX_npVwF4Y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54e87ec-f6be-47b3-c3d7-ec0ecc2816a1"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,10000], 'l1_ratio' : [0.2, 0.4, 0.6]}] \n",
        "grid_search_Elast = GridSearchCV(ElasticNet(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "grid_search_Elast.fit(X_tr_scaled, y_tr)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19197092563540.867, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19410755831724.035, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18884245404054.758, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19152582101650.56, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19356426299891.89, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18838646982877.27, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19101538474132.617, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19288699360467.94, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18786275831733.426, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19957986590040.51, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20218770112552.203, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19660499733845.73, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19809590818908.598, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20065828724589.17, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19510781840061.13, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19631899938733.496, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19880976070609.945, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19328554223341.37, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21884614746423.086, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22238448861530.664, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21610308163892.73, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21532772036031.96, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21805080355965.25, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21254162172010.586, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21097205338478.492, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21392501373329.11, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20789466994621.13, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32363566121254.508, tolerance: 19355927482.514286\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
              "                                  positive=False, precompute=False,\n",
              "                                  random_state=None, selection='cyclic',\n",
              "                                  tol=0.0001, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 10000],\n",
              "                          'l1_ratio': [0.2, 0.4, 0.6]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlhDTD6uBW4L",
        "outputId": "cb847d47-a790-4509-8cd9-5cbb284a7a41"
      },
      "source": [
        "print(grid_search_Elast.best_params_)\n",
        "print(np.sqrt(-grid_search_Elast.best_score_))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 0.1, 'l1_ratio': 0.4}\n",
            "67072.67698457319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cJC9qN3F4Y6"
      },
      "source": [
        "### Evaluating your best model on TESTING data\n",
        "\n",
        "Choose among grid_search_rr, grid_search_lr, and grid_search_enr, the model with best performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOSUoSUsF4Y7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79506743-0100-41df-9a8b-cb39ad250a73"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "final_model = grid_search_lasso.best_estimator_ \n",
        "\n",
        "y_te_estimation = final_model.predict(X_te)\n",
        "\n",
        "final_mse = mean_squared_error(y_te, y_te_estimation)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(final_rmse)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54969194265.36794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIvOOV6lF4Y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1dbec5b2-9705-4338-f2a2-0e4b3abfa3f2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x=y_te, y=y_te_estimation)\n",
        "plt.xlim([-200000,800000])\n",
        "plt.ylim([-200000,800000])\n",
        "plt.show()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HpY_Cn5F4ZF"
      },
      "source": [
        "#[Optional]\n",
        "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joLK71WAF4ZG"
      },
      "source": [
        "## this is due to the nature of matrix multiplication; \n",
        "## the number of columns in matrix A needs to be equal to the number of rows in matrix B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWpjzDr-F4ZI"
      },
      "source": [
        "#[Optional]\n",
        "Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvJTrvGYF4ZI"
      },
      "source": [
        "## No not all gradient descent algorithms lead to the same model. This is due to the fact that it is possible for Gradient Descent algorithms\n",
        "## to get stuck on local extrema or plateau instead of finding a global minimum."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc2htTEMF4ZK"
      },
      "source": [
        "#[Optional]\n",
        "Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkkWmvlnF4ZL"
      },
      "source": [
        "# No due to the nature of Mini-Batch Gradient Descent, the error will fluctuate between increases and decreases in error. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPnLkfrwF4ZO"
      },
      "source": [
        "#[Optional]\n",
        "Suppose you are using Ridge Regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter  or reduce it?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRRVBaaLF1xt"
      },
      "source": [
        "#High error thats equal between the training set and test set is a sign of underfiting. A model that is underfitting is liekly to \n",
        "# have high bias.Therefore, I would reduce regularization to allow for more learning to occur. "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}